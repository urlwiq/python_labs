import re
import sys
import os

sys.path.append(
    os.path.join(
        os.path.dirname(__file__),
        "..",
    )
)
from lib.text import normalize


def tokenize(text: str) -> list[str]:
    regexp = r"[^\w-]"
    text = normalize(re.sub(regexp, " ", text))
    return text.split(" ")


print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))
